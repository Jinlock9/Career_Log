# Task 02-01
- Date: 2025.02.06 ~ 02.07


## 02/06
Now, Machine code sinking is not fully utilizing target's resource parallelism.
Also, it does not consider the latency of each instruction, hurting pipeline efficiency.
- Some codes sunk make instruction scheduling not fully effective.

## 02/07
`Machine Sceduler` performs reasonable scheduling given resources.  
The problem is: the `Machine-sink` inevitably **has the cost**, which is
- As the computations (instructions) are sunk into near their usages, the pipeline efficieny is hurt. This is obvious because there are data dependencies between the computations and their usages. So, the usage instructions should stall extra cycle until the computations are finished. If the computations were not sunk, then data could have already prepared. (Note: this discussion only consider the *pipeline cycles*). Therefore, these code blockes will cause extra cycles whenever they are executed.

The overall performance gains only happen when the program flows of test cases get benefits from newly changed control path by cutting critical edges. Of course, taking new control path also has costs as there are also some sunk codes. However, gains are usually bigger than that (empirical, need to be proved).  

In conclusion, after the `Machine-sink` there will be:
- **Case 1**: Cost of sinking codes not with cutting critical edges `[A]`
- **Case 2**: Gains of sinking codes along with cutting critical edges `[B]` & Cost of sinking codes `[C]`

Thus, the performance would be `[B] - [A] - [C]`. 

### Aproach 1: Only allowing code sinking that involves cutting critical edges
**Case 1** is solely a cost in terms of the number of pipeline cycles. Therefore, trying to reduce `[A]` would be effective for reducing number of cycles.
So, only allow the codes to sink that involve cutting critical edges.

#### Result
See `result1.dat`. It shows 5% performance improve compare to original `machine-sink`. However, only 0.55% improve compare to without machine-sink.
Therefore, we can say that:
- This approach reduces that overheads, not improve the performances.
- Performance degradation with new machine code sink is not larger than 1%. Maybe, this degradation is caused when `[C] > [B]`.

#### TODO:
- More test on `Approach 1`.
- Find the way to **improve** performance.

## Tips
- `docker exec -it heigui-dev /bin/bash`
- `DLCMachineScheduler.cpp`
    - `bool DLCVLIWResourceModel::reserveResources(SUnit *SU, bool IsTop)`
- `DLCTargetMachine.cpp`
    - `DLCPassConfig`, `substitutePass()`
- Debug info

    ```sh
    -misched-dump-schedule-trace --misched-verbose-level=2 --misched-dump-reser
    ved-cycles --sched-print-cycles --debug --debug-only="dlc-machine-scheduler"
    ```
- Compile

    ```sh
    /wkspc/heigui/LLVM/build/bin/llc -mtriple=dlc -enable-dlc-aa=true -large-interval-size-threshold=4 -large-interval-freq-threshold=4 --misched-bottomup --postra-bottomup --force-precise-rotation-cost=true -scheditins=false [.ll] -misched-dump-schedule-trace --misched-verbose-level=2 --misched-dump-reserved-cycles --sched-print-cycles --debug --debug-only="pipeliner,dlc-machine-scheduler" 2>&1
    ```

```
/wkspc/heigui/LLVM/build/bin/clang -target dlc -std=dc99 -emit-llvm -O2 -S ../../dlc_kernels/unfold.c -o unfold.ll

/wkspc/heigui/LLVM/build/bin/llc -mtriple=dlc -enable-dlc-aa=true -large-interval-size-threshold=4 -large-interval-freq-threshold=4 --misched-bottomup --postra-bottomup --force-precise-rotation-cost=true -scheditins=false unfold.ll -misched-dump-schedule-trace --misched-verbose-level=2 --misched-dump-reserved-cycles --sched-print-cycles --debug --debug-only="pipeliner,dlc-machine-scheduler"> log.txt  2>&1
```

- Peephole Optimizations (peephole-opt)
- DLC Remove dead machine instructions (dead-mi-elimination)
- DLC sync flag sinking (dlc-sync-sink)
- Slot index numbering (slotindexes)